{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from tempfile import gettempdir\n",
    "from os.path import join\n",
    "from aequilibrae import Project\n",
    "import shapely.wkb\n",
    "from shapely.geometry import Point\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import perf_counter\n",
    "from copy import deepcopy\n",
    "from aequilibrae.paths import NetworkSkimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an empty project on an arbitrary folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fldr = 'D:/release/Sample models/Chicago_2020_02_15/1_project'\n",
    "fldr = 'D:/GDrive/DATA/Pedro/Professional/Consulting/University of Arkansas/2020-09 - Network criticality analysis/DATA/model'\n",
    "project = Project()\n",
    "project.open(fldr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download the network from any place in the world (as long as you have memory for all the download\n",
    "and data wrangling that will be done)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = project.network\n",
    "network.build_graphs(modes='c')\n",
    "orig_graph = network.graphs['c']\n",
    "orig_nodes_to_indices = orig_graph.nodes_to_indices\n",
    "net = orig_graph.network\n",
    "orig_centroids = orig_graph.centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     44
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network simplification 5.685445899999991\n"
     ]
    }
   ],
   "source": [
    "graph = pd.DataFrame(orig_graph.graph, copy=True)\n",
    "centroids = np.arange(orig_centroids.shape[0])\n",
    "t = perf_counter()\n",
    "\n",
    "# Build link index\n",
    "link_idx = np.empty(net.link_id.max() + 1).astype(np.int)\n",
    "link_idx[net.link_id] = np.arange(net.shape[0])\n",
    "\n",
    "nodes = np.hstack([net.a_node.values, net.b_node.values])\n",
    "links = np.hstack([net.link_id.values, net.link_id.values])\n",
    "\n",
    "idx = np.argsort(nodes)\n",
    "all_nodes = nodes[idx]\n",
    "all_links = links[idx]\n",
    "links_index = np.empty(all_nodes.max() + 1, np.int64)\n",
    "links_index.fill(-1)\n",
    "nlist = np.arange(all_nodes.max())\n",
    "\n",
    "y, x, _ = np.intersect1d(all_nodes, nlist, assume_unique=False, return_indices=True)\n",
    "links_index[y] = x[:]\n",
    "links_index[-1] = all_links.shape[0]\n",
    "for i in range(all_nodes.max(), 1, -1):\n",
    "    links_index[i - 1] = links_index[i] if links_index[i - 1] == -1 else links_index[i - 1]\n",
    "\n",
    "nodes = np.hstack([net.a_node.values, net.b_node.values])\n",
    "counts = np.bincount(nodes)\n",
    "counts[centroids] = 999\n",
    "\n",
    "truth = (counts == 2).astype(np.int)\n",
    "link_edge = truth[net.a_node.values] + truth[net.b_node.values]\n",
    "link_edge = net.link_id.values[link_edge == 1]\n",
    "\n",
    "simplified_links = np.empty(net.link_id.max() + 1)\n",
    "simplified_links.fill(-1)\n",
    "simplified_links = simplified_links.astype(np.int)\n",
    "simplified_directions = np.zeros(net.link_id.max() + 1, np.int)\n",
    "\n",
    "compressed_dir = np.zeros(net.link_id.max() + 1, np.int)\n",
    "compressed_a_node = np.zeros(net.link_id.max() + 1, np.int)\n",
    "compressed_b_node = np.zeros(net.link_id.max() + 1, np.int)\n",
    "\n",
    "slink = 0\n",
    "major_nodes = {}\n",
    "tot = 0\n",
    "tot_graph_add = 0\n",
    "for pre_link in link_edge:\n",
    "    if simplified_links[pre_link] >= 0:\n",
    "        continue\n",
    "    ab_dir = 1\n",
    "    ba_dir = 1\n",
    "    lidx = link_idx[pre_link]\n",
    "    a_node = net.a_node.values[lidx]\n",
    "    b_node = net.b_node.values[lidx]\n",
    "    direction = net.direction.values[lidx]\n",
    "    n = a_node if counts[a_node] == 2 else b_node\n",
    "    first_node = b_node if counts[a_node] == 2 else a_node\n",
    "\n",
    "    ab_dir = 0 if (first_node == a_node and direction < 0) or (first_node == b_node and direction > 0) else ab_dir\n",
    "    ba_dir = 0 if (first_node == a_node and direction > 0) or (first_node == b_node and direction < 0) else ba_dir\n",
    "\n",
    "    while counts[n] == 2:\n",
    "        if simplified_links[pre_link] >= 0:\n",
    "            raise Exception('How the heck did this happen?')\n",
    "        simplified_links[pre_link] = slink\n",
    "        simplified_directions[pre_link] = 1 if a_node == n else -1\n",
    "        for k in range(links_index[n], links_index[n + 1]):\n",
    "            lnk = all_links[k]\n",
    "            if lnk == pre_link:\n",
    "                continue\n",
    "            break\n",
    "        if lnk == pre_link:\n",
    "            raise Exception('How the heck did this happen again?')\n",
    "        pre_link = lnk\n",
    "        lidx = link_idx[pre_link]\n",
    "        a_node = net.a_node.values[lidx]\n",
    "        b_node = net.b_node.values[lidx]\n",
    "        direction = net.direction.values[lidx]\n",
    "        ab_dir = 0 if (n == a_node and direction < 0) or (n == b_node and direction > 0) else ab_dir\n",
    "        ba_dir = 0 if (n == a_node and direction > 0) or (n == b_node and direction < 0) else ba_dir\n",
    "        n = net.a_node.values[lidx] if n == net.b_node.values[lidx] else net.b_node.values[lidx]\n",
    "        direc = 0\n",
    "\n",
    "    if max(ab_dir, ba_dir) < 1:\n",
    "        tot += 1\n",
    "\n",
    "    tot_graph_add += ab_dir + ba_dir\n",
    "    simplified_links[pre_link] = slink\n",
    "    simplified_directions[pre_link] = 1 if a_node == n else -1\n",
    "    last_node = b_node if counts[a_node] == 2 else a_node\n",
    "    major_nodes[slink] = [first_node, last_node]\n",
    "\n",
    "    # Available directions are NOT indexed like the other arrays\n",
    "    compressed_a_node[slink] = first_node\n",
    "    compressed_b_node[slink] = last_node\n",
    "    if ab_dir > 0:\n",
    "        if ba_dir > 0:\n",
    "            compressed_dir[slink] = 0\n",
    "        else:\n",
    "            compressed_dir[slink] = 1\n",
    "    elif ba_dir > 0:\n",
    "        compressed_dir[slink] = -1\n",
    "    else:\n",
    "        compressed_dir[slink] = -999\n",
    "    slink += 1\n",
    "\n",
    "print('Network simplification', perf_counter() - t)\n",
    "\n",
    "t = perf_counter()\n",
    "links_to_remove = np.argwhere(simplified_links >= 0)\n",
    "new_graph = pd.DataFrame(graph, copy=True)\n",
    "new_graph = new_graph[~new_graph.link_id.isin(links_to_remove[:, 0])]\n",
    "\n",
    "indices = pd.DataFrame(graph[['id', 'link_id', 'direction']], copy=True)\n",
    "indices.loc[:, 'link_id'] = graph.link_id * graph.direction\n",
    "indices.set_index('link_id', inplace=True)\n",
    "\n",
    "comp_lnk = pd.DataFrame({'a_node': compressed_a_node[:slink],\n",
    "                         'b_node': compressed_b_node[:slink],\n",
    "                         'direction': compressed_dir[:slink],\n",
    "                         '__augmented_link_id__': np.arange(slink),\n",
    "                         'distance':np.zeros(slink, dtype=np.float64)})\n",
    "comp_lnk.loc[:, 'a_node'] = orig_nodes_to_indices[comp_lnk.a_node]\n",
    "comp_lnk.loc[:, 'b_node'] = orig_nodes_to_indices[comp_lnk.b_node]\n",
    "\n",
    "comp_lnk_ab = pd.DataFrame(comp_lnk[comp_lnk.direction >= 0])\n",
    "comp_lnk_ab.loc[:, 'direction'] = 1\n",
    "\n",
    "comp_lnk_ba = pd.DataFrame(comp_lnk[comp_lnk.direction <= 0])\n",
    "comp_lnk_ba.loc[:, \"direction\"] = -1\n",
    "aux = np.array(comp_lnk_ba.a_node.values, copy=True)\n",
    "comp_lnk_ba.loc[:, \"a_node\"] = comp_lnk_ba.loc[:, \"b_node\"]\n",
    "comp_lnk_ba.loc[:, \"b_node\"] = aux[:]\n",
    "\n",
    "df = pd.concat([new_graph, comp_lnk_ab, comp_lnk_ba])\n",
    "df = df.assign(__new_id__=0)\n",
    "\n",
    "# centroids will not change their IDs, as they are kept the same (the first N nodes in the graph)\n",
    "nodes = np.unique(np.hstack((df.a_node.values, df.b_node.values))).astype(np.int64)\n",
    "nodes = np.setdiff1d(nodes, centroids, assume_unique=True)\n",
    "compress_nodes = np.hstack((centroids, nodes)).astype(np.int64)\n",
    "compress_num_nodes = compress_nodes.shape[0]\n",
    "# nodes_to_indices = np.empty(int(compress_nodes.max()) + 1, np.int64)\n",
    "# nodes_to_indices.fill(-1)\n",
    "nlist = np.arange(compress_num_nodes)\n",
    "# nodes_to_indices[compress_nodes] = nlist\n",
    "num_links = df.shape[0]\n",
    "# df = df.sort_values(by=[\"a_node\", \"b_node\"])\n",
    "# df.loc[:, \"a_node\"] = nodes_to_indices[df.a_node.values][:]\n",
    "# df.loc[:, \"b_node\"] = nodes_to_indices[df.b_node.values][:]\n",
    "df = df.sort_values(by=[\"a_node\", \"b_node\"])\n",
    "df.index = np.arange(df.shape[0])\n",
    "df.loc[:, \"__new_id__\"] = np.arange(df.shape[0])\n",
    "df.loc[:, 'id'] = df.__new_id__[:]\n",
    "compressed_fs = np.empty(compress_num_nodes + 1, dtype=np.int64)\n",
    "compressed_fs.fill(-1)\n",
    "y, x, _ = np.intersect1d(df.a_node.values, nlist, assume_unique=False, return_indices=True)\n",
    "compressed_fs[y] = x[:]\n",
    "compressed_fs[-1] = df.shape[0]\n",
    "for i in range(compress_num_nodes, 1, -1):\n",
    "    if compressed_fs[i - 1] == -1:\n",
    "        compressed_fs[i - 1] = compressed_fs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_graph = deepcopy(orig_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_graph.fs = compressed_fs\n",
    "dummy_graph.graph = df\n",
    "dummy_graph.num_links = df.shape[0]\n",
    "dummy_graph.ids = np.array(df.id.values, np.int64)\n",
    "dummy_graph.set_graph('distance')\n",
    "dummy_graph.set_skimming(['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "skm = NetworkSkimming(dummy_graph)\n",
    "skm.execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
